{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#\n",
    "---\n",
    "# Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, fbeta_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T23:40:51.928371900Z",
     "start_time": "2023-12-02T23:40:44.442207900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#\n",
    "---\n",
    "# Importing Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = np.load('Data/data.npz')\n",
    "trainx = data['arr1']\n",
    "trainy = data['arr2']\n",
    "testx = data['arr3']\n",
    "testy = data['arr4']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#\n",
    "---\n",
    "# Machine Learning Models\n",
    "\n",
    "#### ◉ Logistic Regression (Python)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define the Logistic Regression model\n",
    "model = LogisticRegression(solver='saga', max_iter=100000)\n",
    "\n",
    "# Define the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]\n",
    "}\n",
    "\n",
    "# Create Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model to find the best parameters\n",
    "grid_search.fit(trainx, trainy)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best parameters to create the final model\n",
    "best_model = LogisticRegression(**best_params, solver='saga', max_iter=100000)\n",
    "best_model.fit(trainx, trainy)\n",
    "\n",
    "# Make predictions on the training set\n",
    "trainy_pred = best_model.predict(trainx)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "accuracy_train = accuracy_score(trainy, trainy_pred)\n",
    "print(\"Training Accuracy:\", accuracy_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "testy_pred = best_model.predict(testx)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = accuracy_score(testy, testy_pred)\n",
    "report = classification_report(testy, testy_pred)\n",
    "auc = roc_auc_score(testy, testy_pred)\n",
    "f2 = fbeta_score(testy, testy_pred, beta=2)\n",
    "precision_per_class = precision_score(testy, testy_pred, average=None)\n",
    "\n",
    "# Additional Metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"AUC:\", auc)\n",
    "print(\"F2-score:\", f2)\n",
    "print(\"Precision per class:\", precision_per_class)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Confusion Matrix Visualization\n",
    "plt.rcParams['figure.figsize'] = (4, 4)\n",
    "sns.heatmap(confusion_matrix(testy, testy_pred), annot=True, fmt='d', linewidths=.5, cmap=\"YlGnBu\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# True Positive, True Negative, False Positive, False Negative\n",
    "tp = confusion_matrix(testy, testy_pred)[1][1]\n",
    "tn = confusion_matrix(testy, testy_pred)[0][0]\n",
    "fp = confusion_matrix(testy, testy_pred)[0][1]\n",
    "fn = confusion_matrix(testy, testy_pred)[1][0]\n",
    "\n",
    "print('True Positive Cases: {}'.format(tp))\n",
    "print('True Negative Cases: {}'.format(tn))\n",
    "print('False Positive Cases: {}'.format(fp))\n",
    "print('False Negative Cases: {}'.format(fn))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### ◉ Logistic Regression (Cython + Parallelized GridSearchCV Process)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, fbeta_score, precision_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import parallel_backend\n",
    "import seaborn as sns\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "\n",
    "def logistic_regression_cython(np.ndarray[np.float64_t, ndim=2] trainx, np.ndarray[np.int64_t, ndim=1] trainy, np.ndarray[np.float64_t, ndim=2] testx, np.ndarray[np.int64_t, ndim=1] testy):\n",
    "    # Define the Logistic Regression model\n",
    "    model = LogisticRegression(solver='saga', max_iter=100000)\n",
    "\n",
    "    # Define the parameter grid for Grid Search\n",
    "    param_grid = {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]\n",
    "    }\n",
    "\n",
    "    with parallel_backend('multiprocessing', n_jobs=-1):\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "        # Fit the model to find the best parameters\n",
    "        grid_search.fit(trainx, trainy)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "\n",
    "    # Use the best parameters to create the final model\n",
    "    best_model = LogisticRegression(**best_params, solver='saga', max_iter=100000)\n",
    "    best_model.fit(trainx, trainy)\n",
    "\n",
    "    # Make predictions on the training set\n",
    "    trainy_pred = best_model.predict(trainx)\n",
    "\n",
    "    # Evaluate the model on the training set\n",
    "    accuracy_train = accuracy_score(trainy, trainy_pred)\n",
    "    print(\"Training Accuracy:\", accuracy_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    testy_pred = best_model.predict(testx)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    accuracy = accuracy_score(testy, testy_pred)\n",
    "    report = classification_report(testy, testy_pred)\n",
    "    auc = roc_auc_score(testy, testy_pred)\n",
    "    f2 = fbeta_score(testy, testy_pred, beta=2)\n",
    "    precision_per_class = precision_score(testy, testy_pred, average=None)\n",
    "\n",
    "    # Additional Metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"AUC:\", auc)\n",
    "    print(\"F2-score:\", f2)\n",
    "    print(\"Precision per class:\", precision_per_class)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    # Confusion Matrix Visualization\n",
    "    plt.rcParams['figure.figsize'] = (4, 4)\n",
    "    sns.heatmap(confusion_matrix(testy, testy_pred), annot=True, fmt='d', linewidths=.5, cmap=\"YlGnBu\")\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # True Positive, True Negative, False Positive, False Negative\n",
    "    tp = confusion_matrix(testy, testy_pred)[1][1]\n",
    "    tn = confusion_matrix(testy, testy_pred)[0][0]\n",
    "    fp = confusion_matrix(testy, testy_pred)[0][1]\n",
    "    fn = confusion_matrix(testy, testy_pred)[1][0]\n",
    "\n",
    "    print('True Positive Cases: {}'.format(tp))\n",
    "    print('True Negative Cases: {}'.format(tn))\n",
    "    print('False Positive Cases: {}'.format(fp))\n",
    "    print('False Negative Cases: {}'.format(fn))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "logistic_regression_cython(trainx, trainy, testx, testy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
